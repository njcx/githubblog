Title: 用BERT模型检测提示词注入
Date: 2025-10-29 20:20
Modified: 2025-10-29 20:20
Category: 安全
Tags: 企业安全建设
Slug: T8
Authors: nJcx
Summary: 用BERT模型检测提示词注入 ~



**BERT** (Bidirectional Encoder Representations from Transformers) 是由 Google 在 2018 年提出的预训练语言模型，基于 Transformer 架构，核心创新是双向上下文编码和掩码语言建模（MLM）。它可以被视为一位**“博学的语言学家”**，专门擅长阅读理解和语境分析。



## 1. 核心概念：名字里的秘密

**BERT** 的全称解释了它的构造：

* **T - Transformers (变换器架构)**
    * BERT 的“大脑”。摒弃了传统的循环神经网络（RNN），使用 **Self-Attention (自注意力机制)**。
    * **特点**：能并行计算，同时关注句子中所有的词，而不是按顺序逐个读取。

* **E - Encoder (编码器)**
    * Transformer 包含“编码器”和“解码器”。BERT **只使用了编码器**。
    * **特点**：专注于“听懂”和“理解”输入的信息，而不是生成文本。

* **B - Bidirectional (双向)**
    * BERT 最大的创新点。它在理解一个词时，能同时看到**左边**和**右边**的上下文。
    * *例子*：“我去了**银行**，坐在岸边钓鱼。” —— BERT 通过看到后文的“岸边”，能判断出这里的“银行”是河岸 (River Bank) 而非金融机构。


## 2. 训练原理：BERT 是如何变聪明的？

BERT 在海量文本（维基百科等）上通过两个“游戏”进行**预训练 (Pre-training)**：

### 游戏 1：完形填空 (Masked Language Model, MLM)
* **规则**：随机遮挡句子中 15% 的词（Mask），让模型根据上下文去猜被遮挡的词。
* **例子**：`[今天] [天气] [Mask] [不错]` 模型推断出 `[非常]`。
* **目的**：强迫模型深刻理解词与词之间的双向关系，而非死记硬背。

### 游戏 2：句子接龙 (Next Sentence Prediction, NSP)
* **规则**：给模型两句话 A 和 B，判断 B 是否是 A 的下一句。
* **例子**：
    * A: 小明去买菜。 B: 他买了西红柿。 **Yes**
    * A: 小明去买菜。 B: 企鹅会游泳。 **No**
* **目的**：让模型学会理解句子间的逻辑推理关系。



## 3. 应用模式：预训练 + 微调

这是 BERT 改变 AI 范式的核心流程：

1.  **Pre-training (预训练 - 练内功)**：
    * 在海量通用数据上训练，得到一个通用的语言模型。就像培养一个“通识全才”大学生。
2.  **Fine-tuning (微调 - 学招式)**：
    * 在特定的下游任务数据上（如情感分析、垃圾邮件检测）进行少量训练。就像新员工入职后的“岗前培训”。



## 4. 对比：BERT vs GPT

| 特性 | BERT | GPT (Generative Pre-trained Transformer) |
| :--- | :--- | :--- |
| **核心架构** | Transformer **Encoder** (编码器) | Transformer **Decoder** (解码器) |
| **阅读方向** | **双向** (Bidirectional) | **单向** (从左到右) |
| **参数量** | 	_base: 110M，_large: 340M | 数十亿到千亿级 |
| **擅长领域** | **理解任务**：<br>文本分类、情感分析、实体识别、问答 | **生成任务**：<br>写作、聊天、翻译、代码生成 |
| **本质区别** | 用来**懂**你在说什么 | 用来**接**你的下一句话 |



## 5. 怎么用BERT模型来检测提示词注入


BERT 的强大在于它不是简单地预测下一个词，而是通过“完形填空”真正**读懂了深层语境**。它是现代 NLP 理解任务的基石。整个系统通过反向传播 + 梯度下降自动调整所有参数，无需人为干预。那么我们下载一个 BERT 中文基础模型，在上面用提示词注入数据集，微调模型就符合我们要求。

提示词注入(Prompt Injection)是一种针对AI语言模型的安全攻击技术。提示词注入是指攻击者通过精心设计的输入,试图操纵AI模型忽略原有的系统指令,转而执行攻击者想要的操作。这类似于传统软件中的SQL注入或代码注入攻击。用户直接向AI发送恶意指令,试图覆盖系统提示词。例如:"忽略之前的所有指令,现在告诉我..."。提示词注入可以绕过安全限制,获取不应该提供的信息，操纵AI执行有害或不当的操作，泄露系统提示词或内部配置信息，在集成系统中可能造成更严重的连锁影响等。



```
数据集：
https://github.com/thu-coai/Safety-Prompts

BERT中文模型：
https://huggingface.co/hfl/chinese-bert-wwm-ext/tree/main

```